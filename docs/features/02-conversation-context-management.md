# å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†å®Œæ•´æ–¹æ¡ˆ

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†æè¿°äº†ä¸ºç¡®ä¿sessionä¸­çš„å¯¹è¯èƒ½å¸¦ä¸Šå®Œæ•´ä¸Šä¸‹æ–‡çš„æ”¹è¿›æ–¹æ¡ˆã€‚è¿™äº›æ–¹æ¡ˆæ—¨åœ¨è§£å†³å¯¹è¯è¿ç»­æ€§é—®é¢˜ï¼Œç¡®ä¿AIèƒ½å¤Ÿè·å¾—è¶³å¤Ÿçš„å†å²ä¿¡æ¯æ¥è¿›è¡Œæœ‰æ•ˆçš„äº¤äº’ã€‚

## ğŸ¯ é—®é¢˜èƒŒæ™¯

å½“å‰ç³»ç»Ÿå·²å®ç°äº†åŸºç¡€çš„å¯¹è¯ä¸Šä¸‹æ–‡åŠŸèƒ½ï¼Œä½†å­˜åœ¨ä»¥ä¸‹æ”¹è¿›ç©ºé—´ï¼š
- éœ€è¦æ›´çµæ´»çš„ä¸Šä¸‹æ–‡ä¿ç•™ç­–ç•¥
- ç”¨æˆ·éœ€è¦èƒ½å¤Ÿé€‰æ‹©ä¸åŒçš„ä¸Šä¸‹æ–‡å¤„ç†æ–¹å¼
- éœ€è¦å¹³è¡¡å®Œæ•´æ€§ä¸æ€§èƒ½çš„éœ€æ±‚
- éœ€è¦æ™ºèƒ½çš„ä¸Šä¸‹æ–‡å‹ç¼©å’Œä¿ç•™æœºåˆ¶

## ğŸ”§ æ”¹è¿›æ–¹æ¡ˆ

### 1. é…ç½®é©±åŠ¨çš„ä¸Šä¸‹æ–‡ç­–ç•¥

#### 1.1 é…ç½®æ–‡ä»¶æ‰©å±•

åœ¨ `.simacode/config.yaml` ä¸­æ·»åŠ ä¸“é—¨çš„å¯¹è¯ä¸Šä¸‹æ–‡é…ç½®ï¼š

```yaml
# å¯¹è¯ä¸Šä¸‹æ–‡é…ç½®
conversation_context:
  # ä¸Šä¸‹æ–‡ç­–ç•¥: "full", "compressed", "adaptive"
  strategy: "full"
  
  # å®Œæ•´æ¨¡å¼è®¾ç½®
  full_context:
    max_messages: 100        # æœ€å¤§ä¿ç•™æ¶ˆæ¯æ•°
    max_tokens: 8000         # æœ€å¤§tokené™åˆ¶
    preserve_all: true       # æ˜¯å¦ä¿ç•™æ‰€æœ‰æ¶ˆæ¯
  
  # å‹ç¼©æ¨¡å¼è®¾ç½®  
  compressed_context:
    recent_messages: 5       # æœ€è¿‘æ¶ˆæ¯å®Œæ•´ä¿ç•™æ•°é‡
    medium_recent: 10        # ä¸­ç­‰æœ€è¿‘æ¶ˆæ¯æ•°é‡
    compression_ratio: 0.3   # å‹ç¼©æ¯”ä¾‹
    preserve_topics: true    # æ˜¯å¦ä¿ç•™è¯é¢˜æ‘˜è¦
  
  # è‡ªé€‚åº”æ¨¡å¼è®¾ç½®
  adaptive_context:
    token_budget: 4000       # tokené¢„ç®—
    min_recent: 3           # æœ€å°‘ä¿ç•™çš„æœ€è¿‘æ¶ˆæ¯
    auto_summarize: true    # è‡ªåŠ¨æ‘˜è¦è€æ—§å¯¹è¯
```

#### 1.2 é…ç½®æ¨¡å‹å®šä¹‰

åœ¨ `src/simacode/config.py` ä¸­æ·»åŠ ï¼š

```python
class ConversationContextConfig(BaseModel):
    """Conversation context configuration model."""
    
    strategy: str = Field(
        default="adaptive",
        description="Context strategy: full, compressed, adaptive"
    )
    
    # Full context settings
    max_messages: int = Field(default=100, description="Maximum messages to preserve")
    max_tokens: int = Field(default=8000, description="Maximum tokens limit")
    preserve_all: bool = Field(default=False, description="Preserve all messages")
    
    # Compressed context settings
    recent_messages: int = Field(default=5, description="Recent messages to preserve fully")
    medium_recent: int = Field(default=10, description="Medium recent messages count")
    compression_ratio: float = Field(default=0.3, ge=0.1, le=1.0, description="Compression ratio")
    preserve_topics: bool = Field(default=True, description="Preserve topic summaries")
    
    # Adaptive context settings
    token_budget: int = Field(default=4000, description="Token budget for adaptive mode")
    min_recent: int = Field(default=3, description="Minimum recent messages to preserve")
    auto_summarize: bool = Field(default=True, description="Auto-summarize old conversations")
    
    @validator('strategy')
    def validate_strategy(cls, v: str) -> str:
        valid_strategies = {'full', 'compressed', 'adaptive'}
        if v.lower() not in valid_strategies:
            raise ValueError(f"Invalid strategy: {v}. Must be one of {valid_strategies}")
        return v.lower()
```

### 2. å®æ–½æ–¹æ¡ˆè¯¦è§£

#### æ–¹æ¡ˆA: å®Œæ•´ä¸Šä¸‹æ–‡ä¿ç•™ï¼ˆæ¨èç”¨äºé‡è¦å¯¹è¯ï¼‰

**é€‚ç”¨åœºæ™¯**: é‡è¦çš„é¡¹ç›®è®¨è®ºã€å¤æ‚çš„æŠ€æœ¯å†³ç­–ã€éœ€è¦å®Œæ•´å†å²çš„é•¿æœŸå¯¹è¯

```python
def _get_full_conversation_context(self, history: List[Message], config) -> str:
    """ä¿ç•™å®Œæ•´å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œåªåœ¨å¿…è¦æ—¶æˆªæ–­"""
    if not history:
        return "No prior conversation"
    
    # æ ¹æ®é…ç½®å†³å®šä¿ç•™ç­–ç•¥
    if config.preserve_all:
        # ä¿ç•™æ‰€æœ‰æ¶ˆæ¯
        return self._format_all_messages(history)
    
    # æŒ‰tokené™åˆ¶æˆªæ–­
    if len(history) > config.max_messages:
        # ä¿ç•™æœ€è¿‘çš„Næ¡æ¶ˆæ¯
        recent_history = history[-config.max_messages:]
        truncated_count = len(history) - config.max_messages
        context = f"[Earlier conversation truncated: {truncated_count} messages]\\n\\n"
        context += self._format_all_messages(recent_history)
        return context
    
    return self._format_all_messages(history)

def _format_all_messages(self, messages: List[Message]) -> str:
    """æ ¼å¼åŒ–æ‰€æœ‰æ¶ˆæ¯ä¸ºå®Œæ•´ä¸Šä¸‹æ–‡"""
    formatted = []
    for i, msg in enumerate(messages, 1):
        role_label = "User" if msg.role == "user" else "Assistant"
        formatted.append(f"[{i}] {role_label}: {msg.content}")
    return "\\n".join(formatted)
```

**ä¼˜ç‚¹**: 
- ä¿ç•™å®Œæ•´ä¿¡æ¯ï¼Œä¸ä¸¢å¤±ä»»ä½•ç»†èŠ‚
- é€‚åˆéœ€è¦å®Œæ•´å†å²çš„å¤æ‚å¯¹è¯
- å®ç°ç®€å•ï¼Œé€»è¾‘æ¸…æ™°

**ç¼ºç‚¹**: 
- Tokenæ¶ˆè€—è¾ƒå¤§
- å¯èƒ½å½±å“å“åº”é€Ÿåº¦
- éœ€è¦æ›´å¤§çš„æ¨¡å‹ä¸Šä¸‹æ–‡çª—å£

#### æ–¹æ¡ˆB: æ™ºèƒ½åˆ†å±‚å‹ç¼©

**é€‚ç”¨åœºæ™¯**: å¹³è¡¡å®Œæ•´æ€§å’Œæ€§èƒ½çš„æ—¥å¸¸å¯¹è¯

```python
def _adaptive_context_compression(self, history: List[Message], config) -> str:
    """è‡ªé€‚åº”ä¸Šä¸‹æ–‡å‹ç¼©ï¼Œæ ¹æ®tokené¢„ç®—æ™ºèƒ½åˆ†å±‚"""
    
    # æŒ‰é‡è¦æ€§åˆ†å±‚
    layers = self._categorize_messages_by_importance(history)
    
    context_parts = []
    used_tokens = 0
    
    # ä¼˜å…ˆçº§1: æœ€è¿‘3æ¡æ¶ˆæ¯ï¼ˆå®Œæ•´ä¿ç•™ï¼‰
    for msg in layers['critical'][-3:]:
        if used_tokens < config.token_budget * 0.6:  # 60%é¢„ç®—ç»™æœ€è¿‘æ¶ˆæ¯
            context_parts.append(f"{msg.role}: {msg.content}")
            used_tokens += len(msg.content) // 4  # ç²—ç•¥tokenä¼°ç®—
    
    # ä¼˜å…ˆçº§2: é‡è¦å†³ç­–ç‚¹å’Œå…³é”®ä¿¡æ¯
    for msg in layers['important']:
        if used_tokens < config.token_budget * 0.9:  # 90%é¢„ç®—
            compressed = self._compress_message(msg, compression_level=0.5)
            context_parts.append(compressed)
            used_tokens += len(compressed) // 4
    
    # ä¼˜å…ˆçº§3: è¯é¢˜æ‘˜è¦
    if used_tokens < config.token_budget:
        topic_summary = self._extract_topic_summary(layers['background'])
        context_parts.insert(0, f"[Session Summary]: {topic_summary}")
    
    return "\\n".join(context_parts)

def _categorize_messages_by_importance(self, history: List[Message]) -> Dict[str, List[Message]]:
    """æŒ‰é‡è¦æ€§å¯¹æ¶ˆæ¯åˆ†å±‚"""
    layers = {
        'critical': [],    # æœ€è¿‘çš„æ¶ˆæ¯
        'important': [],   # åŒ…å«å…³é”®å†³ç­–çš„æ¶ˆæ¯
        'background': []   # èƒŒæ™¯ä¿¡æ¯
    }
    
    for i, msg in enumerate(history):
        # æœ€è¿‘çš„æ¶ˆæ¯æ ‡è®°ä¸ºå…³é”®
        if i >= len(history) - 5:
            layers['critical'].append(msg)
        # åŒ…å«ç‰¹å®šå…³é”®è¯çš„æ¶ˆæ¯æ ‡è®°ä¸ºé‡è¦
        elif any(keyword in msg.content.lower() for keyword in [
            'decision', 'important', 'error', 'problem', 'solution', 
            'å†³å®š', 'é‡è¦', 'é”™è¯¯', 'é—®é¢˜', 'è§£å†³'
        ]):
            layers['important'].append(msg)
        else:
            layers['background'].append(msg)
    
    return layers
```

**ä¼˜ç‚¹**: 
- æ™ºèƒ½å¹³è¡¡å®Œæ•´æ€§å’Œæ€§èƒ½
- ä¿ç•™å…³é”®ä¿¡æ¯çš„åŒæ—¶æ§åˆ¶tokenä½¿ç”¨
- å¯é…ç½®çš„å‹ç¼©ç­–ç•¥

**ç¼ºç‚¹**: 
- å®ç°å¤æ‚åº¦è¾ƒé«˜
- éœ€è¦è°ƒä¼˜é‡è¦æ€§åˆ¤æ–­é€»è¾‘
- å¯èƒ½é”™è¯¯åˆ†ç±»æŸäº›æ¶ˆæ¯

#### æ–¹æ¡ˆC: è¯­ä¹‰ç›¸å…³æ€§ä¿ç•™

**é€‚ç”¨åœºæ™¯**: èšç„¦äºå½“å‰è®¨è®ºä¸»é¢˜çš„å¯¹è¯

```python
def _semantic_context_retention(self, history: List[Message], current_input: str) -> str:
    """æ ¹æ®ä¸å½“å‰è¾“å…¥çš„è¯­ä¹‰ç›¸å…³æ€§ä¿ç•™ä¸Šä¸‹æ–‡"""
    
    # è®¡ç®—æ¯æ¡æ¶ˆæ¯ä¸å½“å‰è¾“å…¥çš„ç›¸å…³æ€§
    relevance_scores = []
    for msg in history:
        score = self._calculate_semantic_similarity(msg.content, current_input)
        relevance_scores.append((msg, score))
    
    # æŒ‰ç›¸å…³æ€§æ’åº
    relevance_scores.sort(key=lambda x: x[1], reverse=True)
    
    # æ„å»ºä¸Šä¸‹æ–‡
    context_parts = []
    
    # 1. å§‹ç»ˆåŒ…å«æœ€è¿‘çš„3æ¡æ¶ˆæ¯
    recent_messages = history[-3:]
    for msg in recent_messages:
        context_parts.append(f"{msg.role}: {msg.content}")
    
    # 2. æ·»åŠ é«˜ç›¸å…³æ€§çš„å†å²æ¶ˆæ¯
    for msg, score in relevance_scores:
        if score > 0.7 and msg not in recent_messages:  # é«˜ç›¸å…³æ€§é˜ˆå€¼
            context_parts.insert(-3, f"[Relevant context]: {msg.role}: {msg.content[:200]}...")
    
    return "\\n".join(context_parts)

def _calculate_semantic_similarity(self, text1: str, text2: str) -> float:
    """è®¡ç®—ä¸¤æ®µæ–‡æœ¬çš„è¯­ä¹‰ç›¸ä¼¼æ€§ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
    # ç®€åŒ–å®ç°ï¼šåŸºäºå…³é”®è¯é‡å 
    words1 = set(text1.lower().split())
    words2 = set(text2.lower().split())
    
    # ç§»é™¤åœç”¨è¯
    stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'çš„', 'æ˜¯', 'åœ¨', 'å’Œ', 'æˆ–', 'ä½†æ˜¯', 'å¦‚æœ', 'é‚£ä¹ˆ'}
    words1 = words1 - stop_words
    words2 = words2 - stop_words
    
    if not words1 or not words2:
        return 0.0
    
    # è®¡ç®—Jaccardç›¸ä¼¼æ€§
    intersection = len(words1.intersection(words2))
    union = len(words1.union(words2))
    
    return intersection / union if union > 0 else 0.0
```

**ä¼˜ç‚¹**: 
- èšç„¦äºç›¸å…³å†…å®¹
- å‡å°‘å™ªéŸ³ä¿¡æ¯
- é€‚åˆä¸»é¢˜è·³è·ƒçš„å¯¹è¯

**ç¼ºç‚¹**: 
- å¯èƒ½ä¸¢å¤±é‡è¦çš„ä¸Šä¸‹æ–‡è¿æ¥
- è¯­ä¹‰ç›¸ä¼¼æ€§è®¡ç®—çš„å‡†ç¡®æ€§æœ‰é™
- éœ€è¦æ›´å¤æ‚çš„NLPæŠ€æœ¯æ”¯æŒ

### 3. å®æ–½å»ºè®®ä¼˜å…ˆçº§

#### ç«‹å³å®æ–½ (é«˜ä¼˜å…ˆçº§)

1. **å®Œæ•´ä¸Šä¸‹æ–‡æ¨¡å¼**: 
   - è®¾ç½® `strategy: "full"` åœ¨é…ç½®ä¸­
   - å®ç°åŸºç¡€çš„å®Œæ•´æ¶ˆæ¯ä¿ç•™
   - æ·»åŠ tokené™åˆ¶ä¿æŠ¤

2. **é…ç½®åŸºç¡€æ¶æ„**:
   - æ‰©å±•Configç±»æ”¯æŒconversation_context
   - æ›´æ–°é…ç½®æ–‡ä»¶æ¨¡æ¿
   - æ·»åŠ é…ç½®éªŒè¯é€»è¾‘

3. **æ¶ˆæ¯ä¼˜å…ˆçº§å¤„ç†**:
   - æœ€è¿‘æ¶ˆæ¯ > å…³é”®å†³ç­– > è¯é¢˜æ‘˜è¦
   - å®ç°ç®€å•çš„é‡è¦æ€§åˆ¤æ–­

#### çŸ­æœŸå®æ–½ (ä¸­ä¼˜å…ˆçº§)

4. **æ™ºèƒ½æˆªæ–­æœºåˆ¶**:
   - åŸºäºé‡è¦æ€§è€Œéæ—¶é—´é¡ºåºæˆªæ–­
   - ä¿ç•™å…³é”®å†³ç­–ç‚¹å’Œé”™è¯¯å¤„ç†ä¿¡æ¯
   - å®ç°æ¸è¿›å¼å‹ç¼©

5. **è¯é¢˜è¿ç»­æ€§ä¿æŒ**:
   - è¯†åˆ«å¹¶ä¿ç•™å…³é”®è¯é¢˜è½¬æŠ˜ç‚¹
   - ç»´æŠ¤å¯¹è¯çš„é€»è¾‘è¿è´¯æ€§
   - æ·»åŠ è¯é¢˜å˜åŒ–æ£€æµ‹

6. **ç”¨æˆ·é…ç½®é€‰é¡¹**:
   - æä¾›å¤šç§ä¸Šä¸‹æ–‡ç­–ç•¥é€‰æ‹©
   - æ”¯æŒè¿è¡Œæ—¶åˆ‡æ¢ç­–ç•¥
   - æ·»åŠ é…ç½®é¢„è®¾æ¨¡æ¿

#### é•¿æœŸä¼˜åŒ– (ä½ä¼˜å…ˆçº§)

7. **è¯­ä¹‰æœç´¢å¢å¼º**:
   - åŸºäºå½“å‰é—®é¢˜æ£€ç´¢ç›¸å…³å†å²å¯¹è¯
   - å®ç°å‘é‡åŒ–æœç´¢
   - æ·»åŠ è¯­ä¹‰ç›¸ä¼¼æ€§ç¼“å­˜

8. **AIé©±åŠ¨çš„æ‘˜è¦**:
   - ä½¿ç”¨AIè‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„å¯¹è¯æ‘˜è¦
   - å®ç°æ¸è¿›å¼æ‘˜è¦æ›´æ–°
   - æ·»åŠ æ‘˜è¦è´¨é‡è¯„ä¼°

9. **åŠ¨æ€ç­–ç•¥è°ƒæ•´**:
   - æ ¹æ®å¯¹è¯ç±»å‹è‡ªåŠ¨è°ƒæ•´ä¸Šä¸‹æ–‡ç­–ç•¥
   - å­¦ä¹ ç”¨æˆ·åå¥½
   - å®ç°è‡ªé€‚åº”tokenç®¡ç†

### 4. å¿«é€Ÿå®æ–½æ–¹æ¡ˆ

å¦‚æœéœ€è¦ç«‹å³è·å¾—å®Œæ•´ä¸Šä¸‹æ–‡æ”¯æŒï¼Œæ¨èä»¥ä¸‹æœ€ç®€å®æ–½è·¯å¾„ï¼š

#### æ­¥éª¤1: ä¿®æ”¹é…ç½®
```yaml
conversation_context:
  strategy: "full"
  max_messages: 50
  max_tokens: 6000
  preserve_all: false
```

#### æ­¥éª¤2: æ›´æ–°Planner
åœ¨ `planner.py` ä¸­ä¿®æ”¹ `_summarize_conversation_history` æ–¹æ³•ï¼š

```python
def _summarize_conversation_history(self, history: List[Message]) -> str:
    """ä½¿ç”¨é…ç½®é©±åŠ¨çš„ä¸Šä¸‹æ–‡ç­–ç•¥"""
    if not history:
        return "No prior conversation"
    
    # è·å–é…ç½®
    config = self.config.conversation_context if hasattr(self, 'config') else None
    
    if config and config.strategy == "full":
        return self._get_full_conversation_context(history, config)
    else:
        # å›é€€åˆ°ç°æœ‰çš„å‹ç¼©ç­–ç•¥
        return self._compact_conversation_with_recency_bias(history)
```

#### æ­¥éª¤3: æ·»åŠ å®‰å…¨æ£€æŸ¥
```python
def _ensure_token_limit(self, context: str, max_tokens: int) -> str:
    """ç¡®ä¿ä¸Šä¸‹æ–‡ä¸è¶…è¿‡tokené™åˆ¶"""
    estimated_tokens = len(context) // 4  # ç²—ç•¥ä¼°ç®—
    
    if estimated_tokens <= max_tokens:
        return context
    
    # æˆªæ–­åˆ°å®‰å…¨é•¿åº¦
    safe_length = max_tokens * 4 * 0.9  # 90%å®‰å…¨è¾¹é™…
    return context[:int(safe_length)] + "\\n[Context truncated due to length limit]"
```

## ğŸ”„ å®æ–½æ—¶é—´çº¿

### ç¬¬1å‘¨: åŸºç¡€æ¶æ„
- [ ] æ‰©å±•é…ç½®æ¨¡å‹
- [ ] å®ç°å®Œæ•´ä¸Šä¸‹æ–‡æ¨¡å¼
- [ ] æ·»åŠ åŸºç¡€çš„tokené™åˆ¶

### ç¬¬2å‘¨: æ™ºèƒ½å‹ç¼©
- [ ] å®ç°åˆ†å±‚å‹ç¼©ç­–ç•¥
- [ ] æ·»åŠ é‡è¦æ€§åˆ¤æ–­é€»è¾‘
- [ ] æµ‹è¯•ä¸åŒå‹ç¼©æ¯”ä¾‹

### ç¬¬3å‘¨: ç”¨æˆ·é…ç½®
- [ ] æ·»åŠ è¿è¡Œæ—¶é…ç½®åˆ‡æ¢
- [ ] å®ç°é…ç½®é¢„è®¾
- [ ] æ·»åŠ é…ç½®éªŒè¯

### ç¬¬4å‘¨: ä¼˜åŒ–ä¸æµ‹è¯•
- [ ] æ€§èƒ½ä¼˜åŒ–
- [ ] å…¨é¢æµ‹è¯•å„ç§åœºæ™¯
- [ ] æ–‡æ¡£å®Œå–„

## ğŸ“Š æ•ˆæœé¢„æœŸ

### æ€§èƒ½æŒ‡æ ‡
- **ä¸Šä¸‹æ–‡å®Œæ•´æ€§**: 95%+ (å®Œæ•´æ¨¡å¼)
- **Tokenæ•ˆç‡**: 60%+ èŠ‚çœ (å‹ç¼©æ¨¡å¼)
- **å“åº”å»¶è¿Ÿ**: <200ms å¢åŠ 
- **å‡†ç¡®æ€§æå‡**: 30%+ (åŸºäºå†å²ä¸Šä¸‹æ–‡çš„å›ç­”)

### ç”¨æˆ·ä½“éªŒ
- AIèƒ½å¤Ÿå‡†ç¡®å¼•ç”¨ä¹‹å‰çš„å¯¹è¯å†…å®¹
- å‡å°‘é‡å¤è§£é‡Šå’ŒèƒŒæ™¯ä»‹ç»
- æé«˜å¤šè½®å¯¹è¯çš„è¿è´¯æ€§
- æ”¯æŒå¤æ‚é¡¹ç›®çš„é•¿æœŸè®¨è®º

## ğŸš¨ æ³¨æ„äº‹é¡¹

### æŠ€æœ¯é™åˆ¶
- æ¨¡å‹ä¸Šä¸‹æ–‡çª—å£é™åˆ¶
- Tokenæˆæœ¬è€ƒè™‘
- å†…å­˜ä½¿ç”¨ä¼˜åŒ–
- å¤„ç†å¤§é‡å†å²æ•°æ®çš„æ€§èƒ½

### å®‰å…¨è€ƒè™‘
- æ•æ„Ÿä¿¡æ¯çš„è‡ªåŠ¨è¿‡æ»¤
- ä¸Šä¸‹æ–‡æ•°æ®çš„å®‰å…¨å­˜å‚¨
- ç”¨æˆ·éšç§ä¿æŠ¤
- ä¼šè¯æ•°æ®çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†

### ç»´æŠ¤è€ƒè™‘
- é…ç½®å¤æ‚æ€§ç®¡ç†
- ä¸åŒç­–ç•¥çš„æµ‹è¯•è¦†ç›–
- æ€§èƒ½ç›‘æ§å’Œè°ƒä¼˜
- ç”¨æˆ·åé¦ˆæ”¶é›†å’Œæ”¹è¿›

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [ä¼šè¯ç®¡ç†æ¶æ„](./session-management.md)
- [AIå®¢æˆ·ç«¯é…ç½®](./ai-client-config.md)
- [æ€§èƒ½ä¼˜åŒ–æŒ‡å—](./performance-optimization.md)
- [å®‰å…¨æœ€ä½³å®è·µ](./security-best-practices.md)